{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e69e14cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import sklearn\n",
    "\n",
    "import gzip\n",
    "import random\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "# from implicit import bpr\n",
    "# from surprise import SVD, Reader, Dataset\n",
    "# from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1dea1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cecc30df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readJSON(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        d = json.loads(l)\n",
    "\n",
    "        yield d\n",
    "\n",
    "# For REVIEW data\n",
    "def readJSON_1(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        d = json.loads(l)\n",
    "        u = d['user_id']\n",
    "        n = d['name']\n",
    "        b = d['gmap_id']  # businessID\n",
    "        r = d['rating']\n",
    "        yield u,b,r,n,d\n",
    "\n",
    "# For BUSINESS META-data\n",
    "def readJSON_2(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        d = json.loads(l)\n",
    "        b      = d['gmap_id']  # businessID\n",
    "        cat    = d['category']\n",
    "        coords = (d['latitude'], d['longitude'])\n",
    "        name   = d['name']\n",
    "        #state = d['state']   #<<< shouldn't be \"permanently closed\"\n",
    "        yield b,name,cat,coords\n",
    "        #yield b,cat,coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "79790971",
   "metadata": {},
   "outputs": [],
   "source": [
    "allReviews = []\n",
    "for l in readJSON(\"review-District_of_Columbia_10.json.gz\"):\n",
    "    allReviews.append(l)\n",
    "\n",
    "allMeta = []\n",
    "for l in readJSON(\"meta-District_of_Columbia.json.gz\"):\n",
    "    allMeta.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ce90e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviews by Business ID\n",
    "reviewById = defaultdict(list)\n",
    "\n",
    "for review in allReviews:\n",
    "    gmap_id = review[\"gmap_id\"]\n",
    "    reviewById[gmap_id].append(review)\n",
    "\n",
    "\n",
    "# Reviews by Business ID\n",
    "metaById = defaultdict(list)\n",
    "\n",
    "for meta in allMeta:\n",
    "    gmap_id = meta[\"gmap_id\"]\n",
    "    metaById[gmap_id].append(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c98ad91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "allMetaData = []\n",
    "for l in readJSON_2(\"meta-District_of_Columbia.json.gz\"):\n",
    "    allMetaData.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "30a6df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find the restaurants in the dataset\n",
    "word_list = [\"restaurant\", \"food\", \"pizza\", \"juice\", \"dessert\", \"takeout\", \"sandwich\", \"diner\", \"bar\", \"cocktail\", \"coffee\", \"cafe\", \"deli\"]  #EXPAND, NON-MANUALLY?\n",
    "word_blacklist = [\"barber shop\", \"eyebrow bar\"]\n",
    "\n",
    "restaurant_gmapIDs = set()\n",
    "\n",
    "count=0\n",
    "for i in range(len(allMetaData)):\n",
    "    if(allMetaData[i][2]):\n",
    "        category_list = [word.lower() for word in allMetaData[i][2]]\n",
    "    else:\n",
    "        category_list = []\n",
    "\n",
    "    contains_word             = any(any(word in s for word in word_list) for s in category_list) # true if any word in word_list is contained in somewhere in category_list\n",
    "    contains_blacklisted_word = any(any(word in s for word in word_blacklist) for s in category_list)\n",
    "\n",
    "    if(category_list and contains_word and not contains_blacklisted_word):\n",
    "        #print(category_list)\n",
    "        restaurant_gmapIDs.add(allMetaData[i][0])\n",
    "\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a42f70f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting rid of repeat entries:\n",
    "\n",
    "encountered_ids = set()\n",
    "restaurantMetaData = []\n",
    "\n",
    "for entry in allMetaData:\n",
    "    entry_ID = entry[0]\n",
    "    if entry_ID in restaurant_gmapIDs and entry_ID not in encountered_ids:\n",
    "        restaurantMetaData.append(entry)\n",
    "        encountered_ids.add(entry_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5ddd1b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For every reviewed place that is a restaurant\n",
    "\n",
    "allRestaurantReviews = []\n",
    "for review in allReviews:\n",
    "    u = review[\"user_id\"]\n",
    "    b = review[\"gmap_id\"]\n",
    "    r = review[\"rating\"]\n",
    "\n",
    "    if b in restaurant_gmapIDs:\n",
    "        allRestaurantReviews.append((u,b,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "45613883",
   "metadata": {},
   "outputs": [],
   "source": [
    "userIDs = {}\n",
    "bizIDs = {}\n",
    "interactions = []\n",
    "\n",
    "for u,b,r in allRestaurantReviews:\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not b in bizIDs: bizIDs[b] = len(bizIDs)\n",
    "    interactions.append((u,b,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9cdac49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1d34ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrain = int(len(interactions) * 0.8)\n",
    "nTest = int(len(interactions) * 0.05)\n",
    "nValid = int(len(interactions) * 0.15)\n",
    "interactionsTrain = interactions[:nTrain]\n",
    "interactionsTest = interactions[nTrain:nTrain+nTest]\n",
    "interactionsValid = interactions[nTrain+nTest:]\n",
    "labelsTest = [r for _,_,r in interactionsTest]\n",
    "labelsValid = [r for _,_,r in interactionsValid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4290ddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerBiz = defaultdict(list)\n",
    "bizsPerUser = defaultdict(list)\n",
    "for u,b,r in interactionsTrain:\n",
    "    bizsPerUser[u].append(b)\n",
    "    usersPerBiz[b].append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cf1cf9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a8254e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "## Bias Model              ##\n",
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3f008f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = sum([r for _,_,r in interactionsTrain]) / len(interactionsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a455180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentFactorModelBiasOnly(tf.keras.Model):\n",
    "    def __init__(self, mu, lamb):\n",
    "        super(LatentFactorModelBiasOnly, self).__init__()\n",
    "        # Initialize to average\n",
    "        self.alpha = tf.Variable(mu)\n",
    "        # Initialize to small random values\n",
    "        self.betaU = tf.Variable(tf.random.normal([len(userIDs)],stddev=0.001))\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(bizIDs)],stddev=0.001))\n",
    "        self.lamb = lamb\n",
    "\n",
    "    # Prediction for a single instance (useful for evaluation)\n",
    "    def predict(self, u, i):\n",
    "        p = self.alpha + self.betaU[u] + self.betaI[i]\n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.lamb * (tf.reduce_sum(self.betaU**2) +\\\n",
    "                            tf.reduce_sum(self.betaI**2))\n",
    "    \n",
    "    # Prediction for a sample of instances\n",
    "    def predictSample(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        beta_u = tf.nn.embedding_lookup(self.betaU, u)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        pred = self.alpha + beta_u + beta_i\n",
    "        return pred\n",
    "    \n",
    "    # Loss\n",
    "    def call(self, sampleU, sampleI, sampleR):\n",
    "        pred = self.predictSample(sampleU, sampleI)\n",
    "        r = tf.convert_to_tensor(sampleR, dtype=tf.float32)\n",
    "        return tf.nn.l2_loss(pred - r) / len(sampleR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6dca64ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ce792540",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBiasOnly = LatentFactorModelBiasOnly(mu, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "37baec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingStepBiasOnly(model, interactions):\n",
    "    Nsamples = int(nTrain/1)\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleU, sampleI, sampleR = [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            u,i,r = random.choice(interactions)\n",
    "            sampleU.append(userIDs[u])\n",
    "            sampleI.append(bizIDs[i])\n",
    "            sampleR.append(r)\n",
    "\n",
    "        loss = model(sampleU,sampleI,sampleR)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "        (grad, var) in zip(gradients, model.trainable_variables)\n",
    "        if grad is not None)\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a27ac95f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10, objective = 0.3765776\n"
     ]
    }
   ],
   "source": [
    "old_error = 10\n",
    "for i in range(15):\n",
    "    obj = trainingStepBiasOnly(modelBiasOnly, interactionsTrain)\n",
    "    if (i % 10 == 9): \n",
    "        print(\"iteration \" + str(i+1) + \", objective = \" + str(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "df8e92a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "biasOnlyPredictions =\\\n",
    "    [modelBiasOnly.predict(userIDs[u],bizIDs[i]).numpy() for u,i,_ in interactionsTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d9fc3c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7694666557289634"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(biasOnlyPredictions, labelsTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "232f4cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "## Baseline (pred mean)    ##\n",
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "086611da",
   "metadata": {},
   "outputs": [],
   "source": [
    "alwaysPredictMean = [4.3 for _ in interactionsTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4945ab5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9443056275559695"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(alwaysPredictMean, labelsTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ce9d4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "## Latent Factor Model     ##\n",
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c8fa219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = sum([r for _,_,r in interactionsTrain]) / len(interactionsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c402ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8fdcd089",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentFactorModel(tf.keras.Model):\n",
    "    def __init__(self, mu, K, lamb):\n",
    "        super(LatentFactorModel, self).__init__()\n",
    "        # Initialize to average\n",
    "        self.alpha = tf.Variable(mu)\n",
    "        # Initialize to small random values\n",
    "        self.betaU = tf.Variable(tf.random.normal([len(userIDs)],stddev=0.001))\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(bizIDs)],stddev=0.001))\n",
    "        self.gammaU = tf.Variable(tf.random.normal([len(userIDs),K],stddev=0.001))\n",
    "        self.gammaI = tf.Variable(tf.random.normal([len(bizIDs),K],stddev=0.001))\n",
    "        self.lamb = lamb\n",
    "\n",
    "    # Prediction for a single instance (useful for evaluation)\n",
    "    def predict(self, u, i):\n",
    "        p = self.alpha + self.betaU[u] + self.betaI[i] +\\\n",
    "            tf.tensordot(self.gammaU[u], self.gammaI[i], 1)\n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.lamb * (tf.reduce_sum(self.betaU**2) +\\\n",
    "                            tf.reduce_sum(self.betaI**2) +\\\n",
    "                            tf.reduce_sum(self.gammaU**2) +\\\n",
    "                            tf.reduce_sum(self.gammaI**2))\n",
    "    \n",
    "    # Prediction for a sample of instances\n",
    "    def predictSample(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        beta_u = tf.nn.embedding_lookup(self.betaU, u)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n",
    "        pred = self.alpha + beta_u + beta_i +\\\n",
    "               tf.reduce_sum(tf.multiply(gamma_u, gamma_i), 1)\n",
    "        return pred\n",
    "    \n",
    "    # Loss\n",
    "    def call(self, sampleU, sampleI, sampleR):\n",
    "        pred = self.predictSample(sampleU, sampleI)\n",
    "        r = tf.convert_to_tensor(sampleR, dtype=tf.float32)\n",
    "        return tf.nn.l2_loss(pred - r) / len(sampleR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2c9e01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_size = 2\n",
    "modelLFM = LatentFactorModel(mu, gamma_size, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8a51bb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingStep(model, interactions):\n",
    "    Nsamples = int(nTrain/1)\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleU, sampleI, sampleR = [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            u,i,r = random.choice(interactions)\n",
    "            sampleU.append(userIDs[u])\n",
    "            sampleI.append(bizIDs[i])\n",
    "            sampleR.append(r)\n",
    "\n",
    "        loss = model(sampleU,sampleI,sampleR)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "                              (grad, var) in zip(gradients, model.trainable_variables)\n",
    "                              if grad is not None)\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ca9470f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 5, objective = 0.3883172\n",
      "iteration 10, objective = 0.36982706\n",
      "iteration 15, objective = 0.35706365\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    obj = trainingStep(modelLFM, interactionsTrain)\n",
    "    if (i % 5 == 4): \n",
    "        print(\"iteration \" + str(i+1) + \", objective = \" + str(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2d127563",
   "metadata": {},
   "outputs": [],
   "source": [
    "LFMPredictions = [modelLFM.predict(userIDs[u],bizIDs[i]).numpy() for u,i,_ in interactionsValid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bba3e628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7642740458451497"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(LFMPredictions, labelsValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98275c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
